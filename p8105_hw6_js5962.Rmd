---
title: "p8105_hw6_js5962"
author: "Jiayao Sun"
data: "12/03/2021"
output: github_document
---

```{r setup, echo = FALSE}
library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
library(MASS)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

knitr::opts_chunk$set(
  fig.width = 8,
  fig.height = 6,
  out.width = "90%",
  message = FALSE,
  warning = FALSE,
  error = FALSE
)

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Import and clean the data

```{r clean}
race = c("White", "Black", "Asian", "Puerto_Rican", "Other", "Unkown") 
birthweight_df = 
  read_csv("birthweight.csv") %>%
  #convert numeric to factor
  mutate(
    babysex = factor(recode(babysex, `1` = "male", `2` = "female")),
    malform = factor(recode(malform, `0` = "absent", `1` = "present")),
    frace = factor(race[frace]),
    mrace = factor(race[mrace])
  ) %>%
  #pnumlbw = 0, pnumsga = 0
  dplyr::select(-pnumlbw, -pnumsga) %>% 
  #check for missing data
  drop_na()
```

To find out a fittest regression model, I would use stepwise regression here, for both forward and backward selection.p value should be smaller than 0.05.

```{r backward}
# fit regression using all predictors
mult_fit = lm(bwt ~ ., data = birthweight_df)
summary(mult_fit)

#use one function
Finalstep = stepAIC(mult_fit, direction = 'both', trace = FALSE, k =  3.8415)
summary(Finalstep)  
```

Therefore, we choose babysexmale, bhead, blength, delwt, gaweeks, mheight, mrace, parity, ppwt and smoken as the significant factors.

Then show a plot of model residuals against fitted values.

```{r residual_fit}
birthweight_df %>% 
  add_predictions(Finalstep) %>% 
  add_residuals(Finalstep) %>% 
  ggplot(aes(x = pred, y = resid, alpha = 0.1)) +
  geom_point(color = "darkblue") +
  ggtitle("residuals against fitted values")
```

Sample

```{r sampling}
birthweight_cv =
  crossv_mc(birthweight_df, 80) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

Next, Fit and compare the models

```{r compare_models}
fit_df =
  birthweight_cv %>% 
  mutate(
    Finalstep = 
      map(.x = train, ~stepAIC(lm(bwt ~ ., data = .x), direction = "both", trace = FALSE)),
    bl_ges = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    bh_bl_sex = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmsefinal = map2_dbl(.x = Finalstep,.y = test, ~rmse(model = .x, data = .y)),
    rmsebl = map2_dbl(.x = bl_ges,.y = test, ~rmse(model = .x, data = .y)),
    rmsebh = map2_dbl(.x = bh_bl_sex,.y = test, ~rmse(model = .x, data = .y))
  )
```

Then we can draw the plot.

```{r violinplot}
fit_df %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    rmsefinal:rmsebh,
    names_to = "model",
     values_to = "rmse", 
     names_prefix = "rmse"
   ) %>%
   mutate(
     model = fct_inorder(model)
     ) %>% 
  ggplot(aes(x = model, y = rmse, fill = model, alpha = 0.5)) +
  geom_violin() +
  scale_x_discrete(labels = c("stepwise", "length&gestational", "head&length&sex")) +
  ggtitle("Comparison between three models") +
  scale_fill_discrete(labels = c("stepwise", "length&gestational", "head&length&sex")) +
  ylim(200, 400)
```

## Problem 2

Firstly, we import the weather data by chunk given.

```{r import data}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())
```

Do the bootstrap

```{r bootstrap, warning = FALSE}
weather_boot =
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    model = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    result_r = map(model, broom::glance),
    result_log = map(model, broom::tidy)
   ) %>% 
  dplyr::select(.id, result_r, result_log) %>% 
  unnest(result_r, result_log)
```


Firstly, let's calculate the r square.


```{r r-square}
r_square =
  weather_boot %>% 
  filter(term == "tmin") %>% 
  dplyr::select(r.squared) 
```

Then, make the density plot for r square.
```{r density_r}
r_square %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  xlab("r square") +
  ggtitle("Distribution of r square") +
  theme(plot.title = element_text(hjust = 0.5))
```

The density plot of r square is nearly a normal distribution with average rounding 0.912. It is slightly left skewed because the right side decreases in a steeper line. Since r square is near to 1, the model would fit the data.

For 95% confidence interval.


```{r CI_r}
r_square %>% 
  summarize(
    "2.5%" = quantile(r.squared, 0.025),
    "97.5%" = quantile(r.squared,0.975)
  ) %>% 
  knitr::kable()
```

Then we calculate the $log(\beta_{0} * \beta_{1})$

```{r calculate}
log_cal =
  weather_boot %>% 
  dplyr::select(.id, term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  rename(intercept = "(Intercept)") %>% 
  mutate(
    log = log10(intercept*tmin)
    )
```

Make a density plot for $log(\beta_{0} * \beta_{1})$

```{r density_log}
log_cal %>% 
  ggplot(aes(x = log)) +
  geom_density() + 
  xlab("log(B_0 * B_1)") +
  ggtitle("Distribution of log(B_0 * B_1)") +
  theme(plot.title = element_text(hjust = 0.5))
```

We can see from the plot that the distribution of $log(\beta_{0} * \beta_{1})$ approaches to the normal distribution, but slightly left-skewed. The highest density is around 0.876.

Then, find the 95% confidence interval.

```{r CI_log}
log_cal %>% 
  summarize(
    "2.5%" = quantile(log, 0.025),
    "97.5%" = quantile(log,0.975)
  ) %>% 
  knitr::kable()
```
